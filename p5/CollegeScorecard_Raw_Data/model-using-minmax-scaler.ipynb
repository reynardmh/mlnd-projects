{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sys\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1729\n",
      "Number of rows: 7804\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('MERGED2013_PP.csv')\n",
    "print \"Number of features: {}\".format(len(data.columns))\n",
    "print \"Number of rows: {}\".format(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# potentially interesting features\n",
    "col_desc = {\n",
    "    'C150_4_POOLED': 'Completion 4yr pooled',\n",
    "    'C150_L4_POOLED': 'Completion <4yr pooled',\n",
    "    'CCSIZSET': 'Carnegie classification-Size & settings',\n",
    "    'CCUGPROF': 'Carnegie classification-Undergrad profile ',\n",
    "    'CCBASIC': 'Carnegie classification-basic',\n",
    "    'CONTROL': 'Control (public/private)',\n",
    "    'RET_FT4': 'Retention 4yr',\n",
    "    'RET_FTL4': 'Retention <4yr',\n",
    "    'ACTCMMID': 'ACT',\n",
    "    'SAT_AVG': 'SAT',\n",
    "    'SAT_AVG_ALL': 'SAT all',\n",
    "    'SATVRMID': 'SAT reading',\n",
    "    'SATMTMID': 'SAT math',\n",
    "    'SATWRMID': 'SAT writing',\n",
    "    'AVGFACSAL': 'Avg faculty salary',\n",
    "    'PFTFAC': 'Full time faculty rate',\n",
    "    'ADM_RATE_ALL': 'Admission rate',\n",
    "    'DISTANCEONLY': 'Distance only',\n",
    "    'NPT4_PUB': 'Avg net price title IV institut public',\n",
    "    'NPT4_PRIV': 'Avg net price title IV institut private',\n",
    "    'NUM4_PUB': 'Num Title IV student, public',\n",
    "    'NUM4_PRIV': 'Num Title IV student, private',\n",
    "    'COSTT4_A': 'Avg cost academic year',\n",
    "    'COSTT4_P': 'Avg cost program year',\n",
    "    'TUITIONFEE_IN': 'In state tuition',\n",
    "    'TUITIONFEE_OUT': 'Out of state tuition',\n",
    "    'TUITIONFEE_PROG': 'Tuition fee program year',\n",
    "    'TUITFTE': 'Net revenue per FTE student',\n",
    "    'INEXPFTE': 'Expense per FTE student',\n",
    "    'PCTPELL': '% Pell Grant receiver',\n",
    "    'PCTFLOAN': '% Fed student loan',\n",
    "    'UG25abv': '% undergrad > 25 yr',\n",
    "    'PFTFTUG1_EF': 'Undergrad 1st-time degree seeking',\n",
    "    'UGDS': 'Number of Undergrad degree seeking',\n",
    "    'PAR_ED_PCT_1STGEN': '% 1st gen students',\n",
    "    'PAR_ED_PCT_MS': '% parent education middle school',\n",
    "    'PAR_ED_PCT_HS': '% parent education high school',\n",
    "    'PAR_ED_PCT_PS': '% parent education post secondary',\n",
    "    'DEP_INC_AVG': 'Avg income dependent stu',\n",
    "    'IND_INC_AVG': 'Avg income independent stu',\n",
    "    'DEBT_MDN': 'Median debt',\n",
    "    'GRAD_DEBT_MDN': 'Median debt complete',\n",
    "    'WDRAW_DEBT_MDN': 'Median debt non-completer',\n",
    "}\n",
    "# print len(col_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[sorted(col_desc.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add column that indicates whether it's a less than 4yr college\n",
    "data['L4_COLLEGE'] = data.C150_4_POOLED.isnull()\n",
    "\n",
    "# combine completion data for 4 year and <4 year institution\n",
    "data['C150'] = pd.concat([data.C150_4_POOLED.dropna(), data.C150_L4_POOLED.dropna()]).reindex_like(data)\n",
    "\n",
    "# combine retention data for 4 year and <4 year institution\n",
    "data['RET_FT'] = pd.concat([data.RET_FT4.dropna(), data.RET_FTL4.dropna()]).reindex_like(data)\n",
    "\n",
    "# combine net price title iv for public and private\n",
    "data['NPT4'] = pd.concat([data.NPT4_PRIV.dropna(), data.NPT4_PUB.dropna()]).reindex_like(data)\n",
    "data['NUM4'] = pd.concat([data.NUM4_PRIV.dropna(), data.NUM4_PUB.dropna()]).reindex_like(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num data after removing missing completion and retention rate: 6007\n",
      "Num features: 42\n",
      "(6007, 42)\n"
     ]
    }
   ],
   "source": [
    "# clean up extra columns after combining\n",
    "del_columns = ['NPT4_PUB', 'NPT4_PRIV', 'NUM4_PUB', 'NUM4_PRIV', 'C150_4_POOLED', 'C150_L4_POOLED']\n",
    "for col in del_columns:\n",
    "    if col in data.keys():\n",
    "        del data[col]\n",
    "        del col_desc[col]\n",
    "\n",
    "col_desc['L4_COLLEGE'] = '<4 years college'\n",
    "col_desc['C150'] = 'Completion'\n",
    "col_desc['RET_FT'] = 'Retention'\n",
    "col_desc['NPT4'] = 'Avg net price Title IV'\n",
    "col_desc['NUM4'] = 'Num Title IV student'\n",
    "\n",
    "data = data[~data['C150'].isnull()]\n",
    "data = data[~data['RET_FT'].isnull()]\n",
    "\n",
    "# remove data containing 'PrivacySuppressed'\n",
    "for col in col_desc.keys():\n",
    "    if data.dtypes[col] == 'object':\n",
    "        data[col] = data[col].replace(['PrivacySuppressed'], [float('NaN')]).astype(float)\n",
    "\n",
    "\n",
    "print \"Num data after removing missing completion and retention rate: {}\".format(len(data))\n",
    "print \"Num features: {}\".format(len(data.columns))\n",
    "print data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1210, 25)\n",
      "1210\n",
      "1210\n"
     ]
    }
   ],
   "source": [
    "X = data[['CONTROL', 'DEBT_MDN', 'DEP_INC_AVG', 'GRAD_DEBT_MDN', 'IND_INC_AVG', 'INEXPFTE', 'PAR_ED_PCT_1STGEN', \n",
    "          'PAR_ED_PCT_HS', 'PAR_ED_PCT_MS', 'PAR_ED_PCT_PS', 'PCTFLOAN', 'PCTPELL', 'UG25abv', 'UGDS', \n",
    "          'WDRAW_DEBT_MDN', 'L4_COLLEGE', 'NPT4', 'NUM4', \n",
    "          'PFTFTUG1_EF', 'PFTFAC',\n",
    "          'SAT_AVG_ALL', 'ACTCMMID', 'ADM_RATE_ALL', 'AVGFACSAL', 'COSTT4_A',\n",
    "          'C150', 'RET_FT']].dropna()\n",
    "# y = X[['C150', 'RET_FT']]\n",
    "y1 = X['C150']\n",
    "y2 = X['RET_FT']\n",
    "X = X.drop('C150', 1)\n",
    "X = X.drop('RET_FT', 1)\n",
    "print X.shape\n",
    "print len(y1)\n",
    "print len(y2)\n",
    "# print X.PFTFTUG1_EF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1210, 23)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "tmpX = X[['DEBT_MDN', 'DEP_INC_AVG', 'GRAD_DEBT_MDN', 'IND_INC_AVG', 'INEXPFTE', 'UGDS', 'WDRAW_DEBT_MDN', 'NPT4', \n",
    "          'NUM4', 'SAT_AVG_ALL', 'ACTCMMID', 'AVGFACSAL', 'COSTT4_A']]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaledX = scaler.fit_transform(tmpX)\n",
    "\n",
    "# print np.array(tmpX.ix[0])\n",
    "# print scaledX[0]\n",
    "\n",
    "# X_for_PCA = pd.DataFrame(scaledX)\n",
    "pctX = X[['PAR_ED_PCT_1STGEN', 'PAR_ED_PCT_HS', 'PAR_ED_PCT_MS', 'PAR_ED_PCT_PS', 'PCTFLOAN', 'PCTPELL', 'UG25abv', \n",
    "          'PFTFTUG1_EF', 'PFTFAC', 'ADM_RATE_ALL']]\n",
    "pctX = np.array(pctX)\n",
    "\n",
    "forPcaX = np.concatenate((scaledX, pctX), axis=1)\n",
    "# print scaledX.shape\n",
    "# print pctX.shape\n",
    "print forPcaX.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.16257628e-01   1.73164702e-01   1.12819213e-01   7.91939545e-02\n",
      "   7.80674005e-02   6.51524359e-02   3.85663143e-02   2.91864611e-02\n",
      "   2.18495298e-02   1.80977204e-02   1.31349331e-02   1.03917544e-02\n",
      "   1.01671138e-02   8.62855457e-03   7.64238311e-03   5.54657921e-03\n",
      "   3.96454892e-03   3.27242079e-03   2.96323839e-03   1.27343293e-03\n",
      "   6.59681299e-04   1.85675207e-19   9.47273654e-20]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=forPcaX.shape[1])\n",
    "pca.fit(forPcaX)\n",
    "\n",
    "# print pca.components_\n",
    "print pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1210, 12)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=12)\n",
    "pca.fit(forPcaX)\n",
    "reducedX = pca.transform(forPcaX)\n",
    "print reducedX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1210, 3)\n",
      "(1210, 1)\n",
      "(1210, 12)\n",
      "(1210, 16)\n"
     ]
    }
   ],
   "source": [
    "# add the categorical feature\n",
    "\n",
    "tmp1X = np.array(pd.get_dummies(X['CONTROL']))\n",
    "tmp2X = X['L4_COLLEGE'].astype(int)\n",
    "tmp2X = np.reshape(tmp2X, (len(tmp2X), 1)) \n",
    "print tmp1X.shape\n",
    "print tmp2X.shape\n",
    "print reducedX.shape\n",
    "finalX = np.concatenate((reducedX, tmp1X, tmp2X), axis=1)\n",
    "print finalX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "y1 = np.array(y1)\n",
    "y2 = np.array(y2)\n",
    "X1_train, X1_test, y1_train, y1_test = cv.train_test_split(finalX, y1, train_size=0.8)\n",
    "X2_train, X2_test, y2_train, y2_test = cv.train_test_split(finalX, y2, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_r2score(reg, X, y, test=False):\n",
    "    t = 'test' if test else 'train'\n",
    "    print \"R2 score on {} data: {}\".format(t, metrics.r2_score(y, reg.predict(np.array(X))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4}\n",
      "R2 score on train data: 0.776016731743\n",
      "R2 score on test data: 0.725433541581\n",
      "{'max_depth': 4}\n",
      "R2 score on train data: 0.639101918398\n",
      "R2 score on test data: 0.567485445203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth': range(1,10) } # , 'min_samples_leaf': [4,5,6,7]}\n",
    "scorer = metrics.make_scorer(metrics.r2_score, greater_is_better=True)\n",
    "reg = DecisionTreeRegressor()\n",
    "best_reg = GridSearchCV(reg, parameters, scoring=scorer, cv=3)\n",
    "best_reg.fit(X1_train, y1_train)\n",
    "print best_reg.best_params_\n",
    "\n",
    "print_r2score(best_reg, X1_train, y1_train)\n",
    "print_r2score(best_reg, X1_test, y1_test, test=True)\n",
    "\n",
    "reg = DecisionTreeRegressor()\n",
    "best_reg = GridSearchCV(reg, parameters, scoring=scorer, cv=3)\n",
    "best_reg.fit(X2_train, y2_train)\n",
    "print best_reg.best_params_\n",
    "\n",
    "print_r2score(best_reg, X2_train, y2_train)\n",
    "print_r2score(best_reg, X2_test, y2_test, test=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epsilon': 0.10000000000000001, 'C': 10.0, 'gamma': 0.10000000000000001}\n",
      "R2 score on train data: 0.843993310307\n",
      "R2 score on test data: 0.811862254817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "params = {'C': np.logspace(-1, 1, 2), 'gamma': np.logspace(-1, 1, 2), 'epsilon': np.logspace(-1, 1, 2)}\n",
    "reg = SVR()\n",
    "best_reg = GridSearchCV(reg, params, scoring=scorer, cv=4)\n",
    "best_reg.fit(X1_train, y1_train)\n",
    "\n",
    "print best_reg.best_params_\n",
    "print_r2score(best_reg, X1_train, y1_train)\n",
    "print_r2score(best_reg, X1_test, y1_test, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epsilon': 0.10000000000000001, 'C': 10.0, 'gamma': 0.10000000000000001}\n",
      "R2 score on train data: 0.72439684816\n",
      "R2 score on test data: 0.650611878577\n"
     ]
    }
   ],
   "source": [
    "reg = SVR()\n",
    "params = {'C': np.logspace(-1, 1, 2), 'gamma': np.logspace(-1, 1, 2), 'epsilon': np.logspace(-1, 1, 2)}\n",
    "best_reg = GridSearchCV(reg, params, scoring=scorer, cv=4)\n",
    "best_reg.fit(X2_train, y2_train)\n",
    "\n",
    "print best_reg.best_params_\n",
    "print_r2score(best_reg, X2_train, y2_train)\n",
    "print_r2score(best_reg, X2_test, y2_test, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 10}\n",
      "R2 score on train data: 0.814169201028\n",
      "R2 score on test data: 0.753269058512\n",
      "{'n_neighbors': 12}\n",
      "R2 score on train data: 0.702113916177\n",
      "R2 score on test data: 0.643763198282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "parameters = {'n_neighbors': range(5,20)}\n",
    "reg = KNeighborsRegressor()\n",
    "best_reg = GridSearchCV(reg, parameters, scoring=scorer, cv=2)\n",
    "best_reg.fit(X1_train, y1_train)\n",
    "print best_reg.best_params_\n",
    "print_r2score(best_reg, X1_train, y1_train)\n",
    "print_r2score(best_reg, X1_test, y1_test, test=True)\n",
    "\n",
    "parameters = {'n_neighbors': range(5, 20)}\n",
    "reg = KNeighborsRegressor()\n",
    "best_reg = GridSearchCV(reg, parameters, scoring=scorer, cv=2)\n",
    "best_reg.fit(X2_train, y2_train)\n",
    "print best_reg.best_params_\n",
    "print_r2score(best_reg, X2_train, y2_train)\n",
    "print_r2score(best_reg, X2_test, y2_test, test=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on train data: 0.963511794177\n",
      "R2 score on test data: 0.76295393497\n",
      "R2 score on train data: 0.944744413061\n",
      "R2 score on test data: 0.652043305626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# , max_depth=None, min_samples_split=1, random_state=0\n",
    "reg1 = RandomForestRegressor(n_estimators=10)\n",
    "reg1.fit(X1_train, y1_train)\n",
    "\n",
    "print_r2score(reg1, X1_train, y1_train)\n",
    "print_r2score(reg1, X1_test, y1_test, test=True)\n",
    "\n",
    "reg1 = RandomForestRegressor(n_estimators=10)\n",
    "reg1.fit(X2_train, y2_train)\n",
    "\n",
    "print_r2score(reg1, X2_train, y2_train)\n",
    "print_r2score(reg1, X2_test, y2_test, test=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
