{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sys\n",
    "import p5lib\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6007, 45)\n"
     ]
    }
   ],
   "source": [
    "# load data from csv or pickle (much faster)\n",
    "\n",
    "pickle_file = 'reduced_data.pickle'\n",
    "if os.path.isfile(pickle_file):\n",
    "    data = pickle.load(open(pickle_file, \"rb\"))\n",
    "else:\n",
    "    data = pd.read_csv('MERGED2013_PP.csv')\n",
    "    data = p5lib.preprocess_data(data)\n",
    "    # save data as pickle because it's much faster\n",
    "    pickle.dump(data, open(pickle_file, \"wb\"))\n",
    "\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5930, 28)\n",
      "(5930, 2)\n"
     ]
    }
   ],
   "source": [
    "X = data[['CONTROL', 'DEBT_MDN', 'DEP_INC_AVG', 'GRAD_DEBT_MDN', 'IND_INC_AVG', 'INEXPFTE', 'PAR_ED_PCT_1STGEN', \n",
    "          'PAR_ED_PCT_HS', 'PAR_ED_PCT_MS', 'PAR_ED_PCT_PS', 'PCTFLOAN', 'PCTPELL', 'UG25abv', 'UGDS', \n",
    "          'WDRAW_DEBT_MDN', 'L4_COLLEGE', 'NPT4', 'NUM4', \n",
    "          'PFTFTUG1_EF', 'PFTFAC',\n",
    "          'SAT_AVG_ALL', 'ACTCMMID', 'ADM_RATE_ALL', 'AVGFACSAL', 'COSTT4_A',\n",
    "          'CCSIZSET', 'CCUGPROF', 'CCBASIC', # carnegie classification data (which is not complete)\n",
    "          'C150', 'RET_FT']]\n",
    "\n",
    "# remove noise, there are some with 0 retention but high completion rate, and vice versa (which doesn't make sense\n",
    "# and seems like error in the data)\n",
    "X = X[~((X.RET_FT == 0) & (X.C150 > 0.5))]\n",
    "X = X[~((X.C150 == 0) & (X.RET_FT > 0.5))]\n",
    "X = X[~((X.C150 == 1) & (X.RET_FT < 0.5))]\n",
    "X = X[~((X.RET_FT == 1) & (X.C150 < 0.5))]\n",
    "\n",
    "y = X[['C150', 'RET_FT']]\n",
    "X = X.drop('C150', 1)\n",
    "X = X.drop('RET_FT', 1)\n",
    "print X.shape\n",
    "print y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available data for each feature (not counting the NaN values)\n",
      "CONTROL             Control (public/private)                      5930\n",
      "DEBT_MDN            Median debt                                   5187\n",
      "DEP_INC_AVG         Avg income dependent stu                      5642\n",
      "GRAD_DEBT_MDN       Median debt complete                          5129\n",
      "IND_INC_AVG         Avg income independent stu                    5629\n",
      "INEXPFTE            Expense per FTE student                       5929\n",
      "PAR_ED_PCT_1STGEN   % 1st gen students                            5461\n",
      "PAR_ED_PCT_HS       % parent education high school                5479\n",
      "PAR_ED_PCT_MS       % parent education middle school              5369\n",
      "PAR_ED_PCT_PS       % parent education post secondary             5479\n",
      "PCTFLOAN            % Fed student loan                            5928\n",
      "PCTPELL             % Pell Grant receiver                         5928\n",
      "UG25abv             % undergrad > 25 yr                           5892\n",
      "UGDS                Number of Undergrad degree seeking            5930\n",
      "WDRAW_DEBT_MDN      Median debt non-completer                     4943\n",
      "L4_COLLEGE          <4 years college                              5930\n",
      "NPT4                Avg net price Title IV                        5866\n",
      "NUM4                Num Title IV student                          5866\n",
      "PFTFTUG1_EF         Undergrad 1st-time degree seeking             3250\n",
      "PFTFAC              Full time faculty rate                        3378\n",
      "SAT_AVG_ALL         SAT all                                       1440\n",
      "ACTCMMID            ACT                                           1326\n",
      "ADM_RATE_ALL        Admission rate                                2040\n",
      "AVGFACSAL           Avg faculty salary                            3747\n",
      "COSTT4_A            Avg cost academic year                        3642\n",
      "CCSIZSET            Carnegie classification-Size & settings       3251\n",
      "CCUGPROF            Carnegie classification-Undergrad profile     3251\n",
      "CCBASIC             Carnegie classification-basic                 3591\n"
     ]
    }
   ],
   "source": [
    "p5lib.print_num_data_for_each_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading split_data from pickle\n",
      "(4744, 28)\n",
      "(1186, 28)\n",
      "(4744, 2)\n",
      "(1186, 2)\n",
      "       y_test c150  y_train c150\n",
      "count  1186.000000   4744.000000\n",
      "mean      0.537681      0.526076\n",
      "std       0.232230      0.237625\n",
      "min       0.023489      0.000000\n",
      "25%       0.354547      0.333560\n",
      "50%       0.561215      0.552041\n",
      "75%       0.728422      0.717390\n",
      "max       1.000000      1.000000\n",
      "        y_test ret  y_train ret\n",
      "count  1186.000000  4744.000000\n",
      "mean      0.694168     0.690989\n",
      "std       0.175161     0.173520\n",
      "min       0.000000     0.000000\n",
      "25%       0.593050     0.585400\n",
      "50%       0.712250     0.704500\n",
      "75%       0.818200     0.813500\n",
      "max       1.000000     1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation as cv\n",
    "\n",
    "# Split the data into train & test and keep it the same (so train and test data doesn't keep changing when we test \n",
    "# different ways of building the model)\n",
    "pickle_file = 'split_data.pickle'\n",
    "if os.path.isfile(pickle_file):\n",
    "    print \"loading split_data from pickle\"\n",
    "    split_data = pickle.load(open(pickle_file, \"rb\"))\n",
    "    X_train, X_test, y_train, y_test = split_data['X_train'], split_data['X_test'], split_data['y_train'], split_data['y_test']\n",
    "else:\n",
    "    y = np.array(y)\n",
    "    X_train, X_test, y_train, y_test = cv.train_test_split(X, y, train_size=0.8)\n",
    "    split_data = {\n",
    "        'X_train': X_train,\n",
    "        'X_test':  X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test':  y_test,        \n",
    "    }\n",
    "    pickle.dump(split_data, open(pickle_file, \"wb\"))\n",
    "    \n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape\n",
    "\n",
    "# Check if the train / test has similar distribution\n",
    "print pd.DataFrame(data={'y_train c150': pd.Series(y_train[:,0]).describe(),\n",
    "                         'y_test c150': pd.Series(y_test[:,0]).describe(),\n",
    "                        })\n",
    "print pd.DataFrame(data={'y_train ret': pd.Series(y_train[:,1]).describe(),\n",
    "                         'y_test ret': pd.Series(y_test[:,1]).describe(),\n",
    "                        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_categorical_cols = ['DEBT_MDN', 'DEP_INC_AVG', 'GRAD_DEBT_MDN', 'IND_INC_AVG', 'INEXPFTE', 'WDRAW_DEBT_MDN',\n",
    "                       'PAR_ED_PCT_1STGEN', 'PAR_ED_PCT_HS', 'PAR_ED_PCT_MS', 'PAR_ED_PCT_PS', 'PCTFLOAN', 'PCTPELL', \n",
    "                       'UG25abv', 'NPT4', 'NUM4', 'PFTFTUG1_EF', 'PFTFAC', 'SAT_AVG_ALL', 'ACTCMMID', 'ADM_RATE_ALL', \n",
    "                       'AVGFACSAL', 'COSTT4_A', 'UGDS']\n",
    "\n",
    "# Fill missing values with the means\n",
    "col_mean = {}\n",
    "for col in non_categorical_cols:\n",
    "    if col in X_train:\n",
    "        col_mean[col] = X_train[col].mean()\n",
    "        X_train[col] = X_train[col].fillna(col_mean[col])\n",
    "        X_test[col] = X_test[col].fillna(col_mean[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4744, 23)\n",
      "(1186, 23)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# take features of type cost/money, and percentage (between 0 and 1) and preprocess with standard scaler\n",
    "# and then use these preprocessed features for PCA\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaledX_train = scaler.fit_transform(X_train[non_categorical_cols])\n",
    "scaledX_test = scaler.transform(X_test[non_categorical_cols])\n",
    "print scaledX_train.shape\n",
    "print scaledX_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.24655650e-01   1.24585911e-01   9.71020152e-02   6.92096771e-02\n",
      "   5.83126789e-02   4.75745623e-02   4.23884493e-02   3.96563859e-02\n",
      "   3.40878378e-02   2.76905353e-02   2.53336893e-02   2.23706918e-02\n",
      "   2.17563065e-02   1.64152943e-02   1.13183641e-02   9.20963988e-03\n",
      "   7.61050814e-03   7.27016931e-03   4.97367489e-03   4.51767546e-03\n",
      "   3.17124132e-03   5.08458877e-04   2.80583198e-04]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=scaledX_train.shape[1])\n",
    "pca.fit(scaledX_train)\n",
    "\n",
    "print pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4744, 15)\n",
      "(1186, 15)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=15)\n",
    "pca.fit(scaledX_train)\n",
    "reducedX_train = pca.transform(scaledX_train)\n",
    "reducedX_test = pca.transform(scaledX_test)\n",
    "\n",
    "# reducedX is the chosen top PCA components\n",
    "print reducedX_train.shape\n",
    "print reducedX_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4744, 19)\n",
      "(1186, 19)\n",
      "(4744, 2)\n",
      "(1186, 2)\n"
     ]
    }
   ],
   "source": [
    "# add the categorical features\n",
    "# only CONTROL and L4_COLLEGE because the carnegie classification data is not complete\n",
    "\n",
    "tmp1X = np.array(pd.get_dummies(X_train['CONTROL']))\n",
    "tmp2X = X_train['L4_COLLEGE'].astype(int)\n",
    "tmp2X = np.reshape(tmp2X, (len(tmp2X), 1)) \n",
    "finalX_train = np.concatenate((reducedX_train, tmp1X, tmp2X), axis=1)\n",
    "print finalX_train.shape\n",
    "\n",
    "tmp1X = np.array(pd.get_dummies(X_test['CONTROL']))\n",
    "tmp2X = X_test['L4_COLLEGE'].astype(int)\n",
    "tmp2X = np.reshape(tmp2X, (len(tmp2X), 1)) \n",
    "finalX_test = np.concatenate((reducedX_test, tmp1X, tmp2X), axis=1)\n",
    "print finalX_test.shape\n",
    "\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "{'max_depth': 6}\n",
      "R2 score on train data: 0.628203066121\n",
      "R2 score on test  data: 0.554932450279\n",
      "--- Retention ---\n",
      "{'max_depth': 5}\n",
      "R2 score on train data: 0.329589485813\n",
      "R2 score on test  data: 0.225267074998\n"
     ]
    }
   ],
   "source": [
    "DT_reg1, DT_reg2, _, _ = p5lib.build_DecisionTree_model(finalX_train, finalX_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "{'epsilon': 0.10000000000000001, 'C': 0.10000000000000001, 'gamma': 0.10000000000000001}\n",
      "R2 score on train data: 0.745802250984\n",
      "R2 score on test  data: 0.647835401393\n",
      "--- Retention ---\n",
      "{'epsilon': 0.10000000000000001, 'C': 0.10000000000000001, 'gamma': 0.10000000000000001}\n",
      "R2 score on train data: 0.496864683516\n",
      "R2 score on test  data: 0.313152875409\n"
     ]
    }
   ],
   "source": [
    "SVR_reg1, SVR_reg2, _, _ = p5lib.build_SVR_model(finalX_train, finalX_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "{'n_neighbors': 8}\n",
      "R2 score on train data: 0.754742923815\n",
      "R2 score on test  data: 0.666227406057\n",
      "--- Retention ---\n",
      "{'n_neighbors': 19}\n",
      "R2 score on train data: 0.441614377296\n",
      "R2 score on test  data: 0.329813539016\n"
     ]
    }
   ],
   "source": [
    "KNN_reg1, KNN_reg2, _, _ = p5lib.build_KNN_model(finalX_train, finalX_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "R2 score on train data: 0.949578007476\n",
      "R2 score on test  data: 0.659434508598\n",
      "--- Retention ---\n",
      "R2 score on train data: 0.908819971635\n",
      "R2 score on test  data: 0.316207018986\n"
     ]
    }
   ],
   "source": [
    "RForest_reg1, RForest_reg2, _, _ = p5lib.build_RandomForest_model(finalX_train, finalX_test, y_train, y_test, n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "15\n",
      "34\n",
      "(4744, 36)\n",
      "18\n",
      "14\n",
      "31\n",
      "(1186, 36)\n"
     ]
    }
   ],
   "source": [
    "# add more categorical features\n",
    "# CCSIZSET, CCUGPROF, CCBASIC\n",
    "\n",
    "tmp1X = np.array(pd.get_dummies(X_train['CCSIZSET']))\n",
    "tmp2X = np.array(pd.get_dummies(X_train['CCUGPROF']))\n",
    "tmp3X = np.array(pd.get_dummies(X_train['CCBASIC']))\n",
    "print len(X_train['CCSIZSET'].unique())\n",
    "print len(X_train['CCUGPROF'].unique())\n",
    "print len(X_train['CCBASIC'].unique())\n",
    "\n",
    "r2X_train = np.concatenate((finalX_train, tmp1X), axis=1)\n",
    "print r2X_train.shape\n",
    "\n",
    "tmp1X = np.array(pd.get_dummies(X_test['CCSIZSET']))\n",
    "tmp2X = np.array(pd.get_dummies(X_test['CCUGPROF']))\n",
    "tmp3X = np.array(pd.get_dummies(X_test['CCBASIC']))\n",
    "print len(X_test['CCSIZSET'].unique())\n",
    "print len(X_test['CCUGPROF'].unique())\n",
    "print len(X_test['CCBASIC'].unique())\n",
    "r2X_test = np.concatenate((finalX_test, tmp1X), axis=1)\n",
    "print r2X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "{'max_depth': 6}\n",
      "R2 score on train data: 0.629370742909\n",
      "R2 score on test  data: 0.539633254322\n",
      "--- Retention ---\n",
      "{'max_depth': 5}\n",
      "R2 score on train data: 0.329589485813\n",
      "R2 score on test  data: 0.225267074998\n"
     ]
    }
   ],
   "source": [
    "DT_reg1, DT_reg2, _, _ = p5lib.build_DecisionTree_model(r2X_train, r2X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "{'epsilon': 0.10000000000000001, 'C': 0.10000000000000001, 'gamma': 0.10000000000000001}\n",
      "R2 score on train data: 0.753314727964\n",
      "R2 score on test  data: 0.64912983366\n",
      "--- Retention ---\n",
      "{'epsilon': 0.10000000000000001, 'C': 0.10000000000000001, 'gamma': 0.10000000000000001}\n",
      "R2 score on train data: 0.50500078114\n",
      "R2 score on test  data: 0.312708061307\n"
     ]
    }
   ],
   "source": [
    "SVR_reg1, SVR_reg2, _, _ = p5lib.build_SVR_model(r2X_train, r2X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "{'n_neighbors': 13}\n",
      "R2 score on train data: 0.735691613557\n",
      "R2 score on test  data: 0.671796896921\n",
      "--- Retention ---\n",
      "{'n_neighbors': 19}\n",
      "R2 score on train data: 0.442638528995\n",
      "R2 score on test  data: 0.337837858495\n"
     ]
    }
   ],
   "source": [
    "KNN_reg1, KNN_reg2, _, _ = p5lib.build_KNN_model(r2X_train, r2X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "R2 score on train data: 0.950634832275\n",
      "R2 score on test  data: 0.666180209301\n",
      "--- Retention ---\n",
      "R2 score on train data: 0.909761209959\n",
      "R2 score on test  data: 0.322645207598\n"
     ]
    }
   ],
   "source": [
    "RForest_reg1, RForest_reg2, _, _ = p5lib.build_RandomForest_model(r2X_train, r2X_test, y_train, y_test, n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "R2 score on train data: 0.955347378575\n",
      "R2 score on test  data: 0.672237525277\n",
      "--- Retention ---\n",
      "R2 score on train data: 0.915343761297\n",
      "R2 score on test  data: 0.344088807636\n"
     ]
    }
   ],
   "source": [
    "RForest_reg1, RForest_reg2, _, _ = p5lib.build_RandomForest_model(r2X_train, r2X_test, y_train, y_test, n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "R2 score on train data: 0.955244375152\n",
      "R2 score on test  data: 0.672881830707\n",
      "--- Retention ---\n",
      "R2 score on train data: 0.916929458706\n",
      "R2 score on test  data: 0.339975827444\n"
     ]
    }
   ],
   "source": [
    "p5lib.build_RandomForest_model(r2X_train, r2X_test, y_train, y_test, n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
