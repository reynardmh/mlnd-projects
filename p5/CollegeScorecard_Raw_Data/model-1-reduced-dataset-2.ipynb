{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sys\n",
    "import p5lib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1729\n",
      "Number of rows: 7804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (7,9,1427,1542,1561,1575,1725,1726,1727,1728) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "orig_data = pd.read_csv('MERGED2013_PP.csv')\n",
    "print \"Number of features: {}\".format(len(orig_data.columns))\n",
    "print \"Number of rows: {}\".format(len(orig_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num data after preprocessing: 6007\n",
      "Num features: 42\n",
      "(6007, 42)\n",
      "(7804, 1729)\n"
     ]
    }
   ],
   "source": [
    "data = p5lib.preprocess_data(orig_data)\n",
    "print \"Num data after preprocessing: {}\".format(len(data))\n",
    "print \"Num features: {}\".format(len(data.columns))\n",
    "print data.shape\n",
    "print orig_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1146, 28)\n",
      "(1146, 2)\n"
     ]
    }
   ],
   "source": [
    "X = data[['CONTROL', 'DEBT_MDN', 'DEP_INC_AVG', 'GRAD_DEBT_MDN', 'IND_INC_AVG', 'INEXPFTE', 'PAR_ED_PCT_1STGEN', \n",
    "          'PAR_ED_PCT_HS', 'PAR_ED_PCT_MS', 'PAR_ED_PCT_PS', 'PCTFLOAN', 'PCTPELL', 'UG25abv', 'UGDS', \n",
    "          'WDRAW_DEBT_MDN', 'L4_COLLEGE', 'NPT4', 'NUM4', \n",
    "          'PFTFTUG1_EF', 'PFTFAC',\n",
    "          'CCSIZSET', \n",
    "          'CCUGPROF', \n",
    "          'CCBASIC',\n",
    "          'SAT_AVG_ALL', 'ACTCMMID', 'ADM_RATE_ALL', 'AVGFACSAL', 'COSTT4_A',\n",
    "          'C150', 'RET_FT']].dropna()\n",
    "y = X[['C150', 'RET_FT']]\n",
    "X = X.drop('C150', 1)\n",
    "X = X.drop('RET_FT', 1)\n",
    "print X.shape\n",
    "print y.shape\n",
    "\n",
    "# print X.PFTFTUG1_EF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1146, 23)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "tmpX = X[['DEBT_MDN', 'DEP_INC_AVG', 'GRAD_DEBT_MDN', 'IND_INC_AVG', 'INEXPFTE', 'UGDS', 'WDRAW_DEBT_MDN', 'NPT4', \n",
    "          'NUM4', 'SAT_AVG_ALL', 'ACTCMMID', 'AVGFACSAL', 'COSTT4_A']]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaledX = scaler.fit_transform(tmpX)\n",
    "\n",
    "# print np.array(tmpX.ix[0])\n",
    "# print scaledX[0]\n",
    "\n",
    "# X_for_PCA = pd.DataFrame(scaledX)\n",
    "pctX = X[['PAR_ED_PCT_1STGEN', 'PAR_ED_PCT_HS', 'PAR_ED_PCT_MS', 'PAR_ED_PCT_PS', 'PCTFLOAN', 'PCTPELL', 'UG25abv', \n",
    "          'PFTFTUG1_EF', 'PFTFAC', 'ADM_RATE_ALL']]\n",
    "pctX = np.array(pctX)\n",
    "\n",
    "forPcaX = np.concatenate((scaledX, pctX), axis=1)\n",
    "# print scaledX.shape\n",
    "# print pctX.shape\n",
    "print forPcaX.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.19854866e-01   1.75841822e-01   1.11443415e-01   8.04583938e-02\n",
      "   7.50468911e-02   6.48022317e-02   3.82983398e-02   2.87615885e-02\n",
      "   2.12016136e-02   1.73492140e-02   1.29063607e-02   1.03708261e-02\n",
      "   9.88549630e-03   8.70803199e-03   7.40038246e-03   5.61296309e-03\n",
      "   3.82064432e-03   3.24370756e-03   3.07195858e-03   1.26351122e-03\n",
      "   6.57742160e-04   1.82785104e-19   9.81714648e-20]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=forPcaX.shape[1])\n",
    "pca.fit(forPcaX)\n",
    "\n",
    "# print pca.components_\n",
    "print pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1146, 12)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=12)\n",
    "pca.fit(forPcaX)\n",
    "reducedX = pca.transform(forPcaX)\n",
    "print reducedX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1146, 3)\n",
      "(1146, 1)\n",
      "(1146, 12)\n",
      "(1146, 45)\n"
     ]
    }
   ],
   "source": [
    "# add the categorical feature\n",
    "\n",
    "tmp1X = np.array(pd.get_dummies(X['CONTROL']))\n",
    "tmp2X = X['L4_COLLEGE'].astype(int)\n",
    "tmp2X = np.reshape(tmp2X, (len(tmp2X), 1)) \n",
    "tmp3X = np.array(pd.get_dummies(X['CCSIZSET']))\n",
    "tmp4X = np.array(pd.get_dummies(X['CCUGPROF']))\n",
    "tmp5X = np.array(pd.get_dummies(X['CCBASIC']))\n",
    "\n",
    "print tmp1X.shape\n",
    "print tmp2X.shape\n",
    "print reducedX.shape\n",
    "finalX = np.concatenate((reducedX, tmp1X, tmp2X, tmp3X, tmp4X), axis=1)\n",
    "print finalX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(916, 45)\n",
      "(230, 45)\n",
      "(916, 2)\n",
      "(230, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "y = np.array(y)\n",
    "X_train, X_test, y_train, y_test = cv.train_test_split(finalX, y, train_size=0.8)\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "{'epsilon': 0.10000000000000001, 'C': 0.10000000000000001, 'gamma': 0.10000000000000001}\n",
      "R2 score on train data: 0.814329643919\n",
      "R2 score on test  data: 0.790569146965\n",
      "--- Retention ---\n",
      "{'epsilon': 0.10000000000000001, 'C': 0.10000000000000001, 'gamma': 0.10000000000000001}\n",
      "R2 score on train data: 0.674900144426\n",
      "R2 score on test  data: 0.601001085102\n"
     ]
    }
   ],
   "source": [
    "SVR_reg1, SVR_reg2 = p5lib.build_SVR_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "{'max_depth': 4}\n",
      "R2 score on train data: 0.795096939863\n",
      "R2 score on test  data: 0.720806161046\n",
      "--- Retention ---\n",
      "{'max_depth': 4}\n",
      "R2 score on train data: 0.657596303738\n",
      "R2 score on test  data: 0.534489706059\n"
     ]
    }
   ],
   "source": [
    "DT_reg1, DT_reg2 = p5lib.build_DecisionTree_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 19}\n",
      "R2 score on train data: 0.769164951082\n",
      "R2 score on test  data: 0.745489246874\n",
      "{'n_neighbors': 17}\n",
      "R2 score on train data: 0.645862837857\n",
      "R2 score on test  data: 0.640041457702\n"
     ]
    }
   ],
   "source": [
    "KNN_reg1, KNN_reg2 = p5lib.build_KNN_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on train data: 0.964493957909\n",
      "R2 score on test  data: 0.784462021921\n",
      "R2 score on train data: 0.942971826013\n",
      "R2 score on test  data: 0.690069719749\n"
     ]
    }
   ],
   "source": [
    "RForest_reg1, RForest_reg2 = p5lib.build_RandomForest_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
