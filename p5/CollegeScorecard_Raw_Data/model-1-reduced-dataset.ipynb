{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sys\n",
    "import p5lib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1729\n",
      "Number of rows: 7804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (7,9,1427,1542,1561,1575,1725,1726,1727,1728) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('MERGED2013_PP.csv')\n",
    "print \"Number of features: {}\".format(len(data.columns))\n",
    "print \"Number of rows: {}\".format(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num data after preprocessing: 6007\n",
      "Num features: 42\n"
     ]
    }
   ],
   "source": [
    "data = p5lib.preprocess_data(data)\n",
    "print \"Num data after preprocessing: {}\".format(len(data))\n",
    "print \"Num features: {}\".format(len(data.columns))\n",
    "# print data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1210, 25)\n",
      "(1210, 2)\n"
     ]
    }
   ],
   "source": [
    "X = data[['CONTROL', 'DEBT_MDN', 'DEP_INC_AVG', 'GRAD_DEBT_MDN', 'IND_INC_AVG', 'INEXPFTE', 'PAR_ED_PCT_1STGEN', \n",
    "          'PAR_ED_PCT_HS', 'PAR_ED_PCT_MS', 'PAR_ED_PCT_PS', 'PCTFLOAN', 'PCTPELL', 'UG25abv', 'UGDS', \n",
    "          'WDRAW_DEBT_MDN', 'L4_COLLEGE', 'NPT4', 'NUM4', \n",
    "          'PFTFTUG1_EF', 'PFTFAC',\n",
    "          'SAT_AVG_ALL', 'ACTCMMID', 'ADM_RATE_ALL', 'AVGFACSAL', 'COSTT4_A',\n",
    "          'C150', 'RET_FT']].dropna()\n",
    "y = X[['C150', 'RET_FT']]\n",
    "X = X.drop('C150', 1)\n",
    "X = X.drop('RET_FT', 1)\n",
    "print X.shape\n",
    "print y.shape\n",
    "\n",
    "# print X.PFTFTUG1_EF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1210, 23)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "tmpX = X[['DEBT_MDN', 'DEP_INC_AVG', 'GRAD_DEBT_MDN', 'IND_INC_AVG', 'INEXPFTE', 'UGDS', 'WDRAW_DEBT_MDN', 'NPT4', \n",
    "          'NUM4', 'SAT_AVG_ALL', 'ACTCMMID', 'AVGFACSAL', 'COSTT4_A']]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaledX = scaler.fit_transform(tmpX)\n",
    "\n",
    "# print np.array(tmpX.ix[0])\n",
    "# print scaledX[0]\n",
    "\n",
    "# X_for_PCA = pd.DataFrame(scaledX)\n",
    "pctX = X[['PAR_ED_PCT_1STGEN', 'PAR_ED_PCT_HS', 'PAR_ED_PCT_MS', 'PAR_ED_PCT_PS', 'PCTFLOAN', 'PCTPELL', 'UG25abv', \n",
    "          'PFTFTUG1_EF', 'PFTFAC', 'ADM_RATE_ALL']]\n",
    "pctX = np.array(pctX)\n",
    "\n",
    "forPcaX = np.concatenate((scaledX, pctX), axis=1)\n",
    "# print scaledX.shape\n",
    "# print pctX.shape\n",
    "print forPcaX.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.16257628e-01   1.73164702e-01   1.12819213e-01   7.91939545e-02\n",
      "   7.80674005e-02   6.51524359e-02   3.85663143e-02   2.91864611e-02\n",
      "   2.18495298e-02   1.80977204e-02   1.31349331e-02   1.03917544e-02\n",
      "   1.01671138e-02   8.62855457e-03   7.64238311e-03   5.54657921e-03\n",
      "   3.96454892e-03   3.27242079e-03   2.96323839e-03   1.27343293e-03\n",
      "   6.59681299e-04   1.85675207e-19   9.47273654e-20]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=forPcaX.shape[1])\n",
    "pca.fit(forPcaX)\n",
    "\n",
    "# print pca.components_\n",
    "print pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1210, 12)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=12)\n",
    "pca.fit(forPcaX)\n",
    "reducedX = pca.transform(forPcaX)\n",
    "print reducedX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1210, 3)\n",
      "(1210, 1)\n",
      "(1210, 12)\n",
      "(1210, 16)\n"
     ]
    }
   ],
   "source": [
    "# add the categorical feature\n",
    "\n",
    "tmp1X = np.array(pd.get_dummies(X['CONTROL']))\n",
    "tmp2X = X['L4_COLLEGE'].astype(int)\n",
    "tmp2X = np.reshape(tmp2X, (len(tmp2X), 1)) \n",
    "print tmp1X.shape\n",
    "print tmp2X.shape\n",
    "print reducedX.shape\n",
    "finalX = np.concatenate((reducedX, tmp1X, tmp2X), axis=1)\n",
    "print finalX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(968, 16)\n",
      "(242, 16)\n",
      "(968, 2)\n",
      "(242, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "y = np.array(y)\n",
    "X_train, X_test, y_train, y_test = cv.train_test_split(finalX, y, train_size=0.8)\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "{'epsilon': 0.10000000000000001, 'C': 10.0, 'gamma': 0.10000000000000001}\n",
      "R2 score on train data: 0.836148187689\n",
      "R2 score on test  data: 0.855539869796\n",
      "--- Retention ---\n",
      "{'epsilon': 0.10000000000000001, 'C': 10.0, 'gamma': 0.10000000000000001}\n",
      "R2 score on train data: 0.731973026171\n",
      "R2 score on test  data: 0.684036831879\n"
     ]
    }
   ],
   "source": [
    "SVR_reg1, SVR_reg2, _, _ = p5lib.build_SVR_model(X_train, X_test, y_train, y_test, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion\n",
      "{'max': 0.83956093204131377, 'min': 0.78356904012636397, 'mean': 0.81717572131852967}\n",
      "Retention\n",
      "{'max': 0.72473207987117183, 'min': 0.61400225708686573, 'mean': 0.68153504135791765}\n"
     ]
    }
   ],
   "source": [
    "import StringIO\n",
    "import os\n",
    "\n",
    "reg1_r2scores = []\n",
    "reg2_r2scores = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    # suppress output\n",
    "    actualstdout = sys.stdout\n",
    "    sys.stdout = open(os.devnull,'w')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = cv.train_test_split(finalX, y, train_size=0.8)\n",
    "    SVR_reg1, SVR_reg2, r2score_reg1, r2score_reg2 = p5lib.build_SVR_model(X_train, X_test, y_train, y_test, cv=3)\n",
    "    reg1_r2scores.append(r2score_reg1)\n",
    "    reg2_r2scores.append(r2score_reg2)\n",
    "    \n",
    "    sys.stdout = actualstdout\n",
    "\n",
    "reg1_r2scores = pd.Series(reg1_r2scores)\n",
    "reg2_r2scores = pd.Series(reg2_r2scores)\n",
    "print 'Completion'\n",
    "print { 'mean': reg1_r2scores.mean(), 'min': reg1_r2scores.min(), 'max': reg1_r2scores.max()}\n",
    "print 'Retention'\n",
    "print { 'mean': reg2_r2scores.mean(), 'min': reg2_r2scores.min(), 'max': reg2_r2scores.max()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max': 0.80470296893166549, 'min': 0.73363035870909699, 'mean': 0.7624127056167882}\n",
      "{'max': 0.70170586303884319, 'min': 0.53507422549106343, 'mean': 0.62804086732217324}\n"
     ]
    }
   ],
   "source": [
    "import StringIO\n",
    "import os\n",
    "\n",
    "reg1_r2scores = []\n",
    "reg2_r2scores = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    # suppress output\n",
    "    actualstdout = sys.stdout\n",
    "    sys.stdout = open(os.devnull,'w')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = cv.train_test_split(finalX, y, train_size=0.8)\n",
    "    RForest_reg1, RForest_reg2, r2score_reg1, r2score_reg2 = p5lib.build_RandomForest_model(X_train, X_test, y_train, y_test)\n",
    "    reg1_r2scores.append(r2score_reg1)\n",
    "    reg2_r2scores.append(r2score_reg2)\n",
    "    \n",
    "    sys.stdout = actualstdout\n",
    "\n",
    "reg1_r2scores = pd.Series(reg1_r2scores)\n",
    "reg2_r2scores = pd.Series(reg2_r2scores)\n",
    "print { 'mean': reg1_r2scores.mean(), 'min': reg1_r2scores.min(), 'max': reg1_r2scores.max()}\n",
    "print { 'mean': reg2_r2scores.mean(), 'min': reg2_r2scores.min(), 'max': reg2_r2scores.max()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "{'max_depth': 4}\n",
      "R2 score on train data: 0.77140151644\n",
      "R2 score on test  data: 0.723636190382\n",
      "--- Retention ---\n",
      "{'max_depth': 5}\n",
      "R2 score on train data: 0.678754749055\n",
      "R2 score on test  data: 0.537779045943\n"
     ]
    }
   ],
   "source": [
    "DT_reg1, DT_reg2, _, _ = p5lib.build_DecisionTree_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "{'n_neighbors': 10}\n",
      "R2 score on train data: 0.805969068461\n",
      "R2 score on test  data: 0.797017288787\n",
      "--- Retention ---\n",
      "{'n_neighbors': 8}\n",
      "R2 score on train data: 0.720316124959\n",
      "R2 score on test  data: 0.675495843147\n"
     ]
    }
   ],
   "source": [
    "KNN_reg1, KNN_reg2, _, _ = p5lib.build_KNN_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Completion ---\n",
      "R2 score on train data: 0.970056318763\n",
      "R2 score on test  data: 0.823416434527\n",
      "--- Retention ---\n",
      "R2 score on train data: 0.956607423124\n",
      "R2 score on test  data: 0.685115073209\n"
     ]
    }
   ],
   "source": [
    "RForest_reg1, RForest_reg2, _, _ = p5lib.build_RandomForest_model(X_train, X_test, y_train, y_test, n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823621328721\n",
      "0.67278256995\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 1,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "reg1 = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "y1_train, y1_test, y2_train, y2_test = p5lib.split_y(y_train, y_test)\n",
    "\n",
    "reg1.fit(X_train, y1_train)\n",
    "# print reg.best_params_\n",
    "print metrics.r2_score(y1_test, reg1.predict(X_test))\n",
    "\n",
    "\n",
    "reg2 = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "\n",
    "reg2.fit(X_train, y2_train)\n",
    "# print reg.best_params_\n",
    "print metrics.r2_score(y2_test, reg2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
